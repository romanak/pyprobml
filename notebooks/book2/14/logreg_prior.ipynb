{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec66d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on figure 3 of \"Bayesian workflow\",\n",
    "# https://arxiv.org/abs/2011.01808\n",
    "\n",
    "# Code is modified from Osvaldo Martin et al,\n",
    "# \"Bayesian Modeling and Comptuation In Python\"\n",
    "# https://github.com/aloctavodia/BMCP/blob/master/Code/chp_01bis/chp_01bis_prior_posterior_checks.ipynb\n",
    "\n",
    "# The use of Cauchy priors for logistic regression coefficients is discussed in\n",
    "# https://arxiv.org/abs/1507.07170\n",
    "\n",
    "\n",
    "try:\n",
    "    import probml_utils as pml\n",
    "except ModuleNotFoundError:\n",
    "    %pip install git+https://github.com/probml/probml-utils.git\n",
    "    import probml_utils as pml\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "try:\n",
    "    import arviz as az\n",
    "except ModuleNotFoundError:\n",
    "    %pip install arviz\n",
    "    import arviz as az\n",
    "from scipy.special import expit\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def make_plot_panel(dims, sigmas, student_prior=False, standardize=False):\n",
    "    N = len(dims)\n",
    "    fig, axes = plt.subplots(1, N, figsize=(N * 3, 5), sharex=True, sharey=True)\n",
    "    axes = np.ravel(axes)\n",
    "    np.random.seed(0)\n",
    "    nbetas = 10000  # num random parameters to try\n",
    "    ndata = 500  # num. observations for each beta\n",
    "    for i in range(N):\n",
    "        dim = dims[i]\n",
    "        ax = axes[i]\n",
    "        sigma = sigmas[i]\n",
    "        if student_prior:\n",
    "            df = 3  # 1=Cauchy\n",
    "            prior = stats.t(df, 0, sigma)\n",
    "        else:\n",
    "            prior = stats.norm(0, sigma)\n",
    "        β = prior.rvs((nbetas, dim))\n",
    "        X = np.random.binomial(n=1, p=0.8, size=(dim, ndata))\n",
    "        # X = stats.norm(0, 1).rvs((dim, ndata))\n",
    "        if standardize:\n",
    "            # X = 2*X - 1 # map from [0,1] to [-1,1]\n",
    "            # X = X*0.5 # map to [-0.5, 0.5]\n",
    "            scaler = StandardScaler()\n",
    "            X = scaler.fit_transform(X.T).T\n",
    "        ys = np.random.binomial(n=1, p=expit(β @ X))  # size nbetas * ndata\n",
    "        az.plot_kde(ys.mean(1), ax=ax)  # mean over ndata, kde over nbetas\n",
    "        if student_prior:\n",
    "            ax.set_title(\"{:d} predictors, std={:0.2f}, student prior\".format(dim, sigma))\n",
    "        else:\n",
    "            ax.set_title(\"{:d} predictors, std={:0.2f}\".format(dim, sigma))\n",
    "\n",
    "\n",
    "dims = np.array([1, 5, 15])\n",
    "sigmas = 1.5 * np.ones(3)\n",
    "make_plot_panel(dims, sigmas)\n",
    "pml.savefig(\"logreg_prior_binary_features.pdf\", dpi=300)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
