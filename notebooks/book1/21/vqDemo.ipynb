{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c8f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Quantization Demo\n",
    "# Author: Animesh Gupta\n",
    "\n",
    "# Use racoon face image\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.face.html\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    from sklearn import cluster\n",
    "except ModuleNotFoundError:\n",
    "    %pip install scikit-learn\n",
    "    from sklearn import cluster\n",
    "try:\n",
    "    import probml_utils as pml\n",
    "except ModuleNotFoundError:\n",
    "    %pip install git+https://github.com/probml/probml-utils.git\n",
    "    import probml_utils as pml\n",
    "\n",
    "try:  # SciPy >= 0.16 have face in misc\n",
    "    from scipy.misc import face\n",
    "\n",
    "    face = face(gray=True)\n",
    "except ImportError:\n",
    "    face = sp.face(gray=True)\n",
    "\n",
    "n_clusters = [2, 4]\n",
    "np.random.seed(0)\n",
    "\n",
    "X = face.reshape((-1, 1))  # We need an (n_sample, n_feature) array\n",
    "for n_cluster in n_clusters:\n",
    "    k_means = cluster.KMeans(n_clusters=n_cluster, n_init=4)\n",
    "    k_means.fit(X)\n",
    "    values = k_means.cluster_centers_.squeeze()\n",
    "    labels = k_means.labels_\n",
    "\n",
    "    # create an array from labels and values\n",
    "    face_compressed = np.choose(labels, values)\n",
    "    face_compressed.shape = face.shape\n",
    "\n",
    "    vmin = face.min()\n",
    "    vmax = face.max()\n",
    "\n",
    "    # compressed face\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.title(f\"K = {n_cluster}\")\n",
    "    plt.imshow(face_compressed, cmap=plt.cm.gray, vmin=vmin, vmax=vmax)\n",
    "    pml.savefig(f\"vectorQuantization_{n_cluster}.pdf\", dpi=300)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
